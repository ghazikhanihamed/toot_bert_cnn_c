Interactive jobs timeout is 24hrs
==========================================
SLURM_JOB_ID = 376
SLURM_NODELIST = virya3
==========================================
Tue Feb 20 14:24:45 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:81:00.0 Off |                   On |
| N/A   23C    P0              41W / 400W |     74MiB / 40960MiB |     N/A      Default |
|                                         |                      |              Enabled |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| MIG devices:                                                                          |
+------------------+--------------------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |
|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |
|                  |                                |        ECC|                       |
|==================+================================+===========+=======================|
|  0    1   0   0  |              37MiB / 19968MiB  | 42      0 |  3   0    2    0    0 |
|                  |               0MiB / 32767MiB  |           |                       |
+------------------+--------------------------------+-----------+-----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.weight', 'esm.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_generate_rep_new.py:136: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_train_fold = [torch.tensor(x, dtype=torch.float) for x in X_train_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_generate_rep_new.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_val_fold = [torch.tensor(x, dtype=torch.float) for x in X_val_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_generate_rep_new.py:136: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_train_fold = [torch.tensor(x, dtype=torch.float) for x in X_train_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_generate_rep_new.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_val_fold = [torch.tensor(x, dtype=torch.float) for x in X_val_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_generate_rep_new.py:136: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_train_fold = [torch.tensor(x, dtype=torch.float) for x in X_train_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_generate_rep_new.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_val_fold = [torch.tensor(x, dtype=torch.float) for x in X_val_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_generate_rep_new.py:136: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_train_fold = [torch.tensor(x, dtype=torch.float) for x in X_train_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_generate_rep_new.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_val_fold = [torch.tensor(x, dtype=torch.float) for x in X_val_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_generate_rep_new.py:136: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_train_fold = [torch.tensor(x, dtype=torch.float) for x in X_train_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_generate_rep_new.py:138: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_val_fold = [torch.tensor(x, dtype=torch.float) for x in X_val_fold]
Model saved to ./final_models/final_model_generated_rep_IC_IT.pt
