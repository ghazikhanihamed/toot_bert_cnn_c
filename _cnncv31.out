Interactive jobs timeout is 24hrs
==========================================
SLURM_JOB_ID = 31
SLURM_NODELIST = virya3
==========================================
Sat Feb 17 12:38:18 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:41:00.0 Off |                   On |
| N/A   24C    P0              41W / 400W |     74MiB / 40960MiB |     N/A      Default |
|                                         |                      |              Enabled |
+-----------------------------------------+----------------------+----------------------+

+---------------------------------------------------------------------------------------+
| MIG devices:                                                                          |
+------------------+--------------------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |                   Memory-Usage |        Vol|      Shared           |
|      ID  ID  Dev |                     BAR1-Usage | SM     Unc| CE ENC DEC OFA JPG    |
|                  |                                |        ECC|                       |
|==================+================================+===========+=======================|
|  0    1   0   0  |              37MiB / 19968MiB  | 42      0 |  3   0    2    0    0 |
|                  |               0MiB / 32767MiB  |           |                       |
+------------------+--------------------------------+-----------+-----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_new.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_train_fold = [torch.tensor(x, dtype=torch.float) for x in X_train_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_new.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_val_fold = [torch.tensor(x, dtype=torch.float) for x in X_val_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_new.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_train_fold = [torch.tensor(x, dtype=torch.float) for x in X_train_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_new.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_val_fold = [torch.tensor(x, dtype=torch.float) for x in X_val_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_new.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_train_fold = [torch.tensor(x, dtype=torch.float) for x in X_train_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_new.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_val_fold = [torch.tensor(x, dtype=torch.float) for x in X_val_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_new.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_train_fold = [torch.tensor(x, dtype=torch.float) for x in X_train_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_new.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_val_fold = [torch.tensor(x, dtype=torch.float) for x in X_val_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_new.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_train_fold = [torch.tensor(x, dtype=torch.float) for x in X_train_fold]
/home/h_ghazik/toot_bert_cnn_c/cnn_cv_new.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  X_val_fold = [torch.tensor(x, dtype=torch.float) for x in X_val_fold]
Model saved to ./final_models//final_model_IC_IT.pt
